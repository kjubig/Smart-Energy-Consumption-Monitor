# Smart Energy Consumption Monitor

**Autorzy:** Åukasz Kubik 193178 & Nikodem Kozak 193388 (ACiR KSD)

> System do strumieniowego monitoringu zuÅ¼ycia energii: **Producer â†’ Kafka â†’ Spark (Structured Streaming) â†’ Kafka (alerty) â†’ Streamlit UI**. Uruchamiane jednym `docker compose` na **AWS EC2** (lub lokalnie).

---

## Spis treÅ›ci

* [1) Cel i zakres](#1-cel-i-zakres)
* [2) Strategia i architektura](#2-strategia-i-architektura)
* [3) Technologie i deployment](#3-technologie-i-deployment)
* [4) Struktura repo i odpowiedzialnoÅ›ci](#4-struktura-repo-i-odpowiedzialnoÅ›ci)
* [5) Kluczowe mechanizmy i funkcje](#5-kluczowe-mechanizmy-i-funkcje)
* [6) Uruchomienie na AWS EC2 (krok po kroku)](#6-uruchomienie-na-aws-ec2-krok-po-kroku)
* [7) PrzeÅ‚Ä…czanie trybu demo/prod](#7-przeÅ‚Ä…czanie-trybu-demoprod)
* [8) Co pokazaÄ‡ na prezentacji + miejsce na wykresy](#8-co-pokazaÄ‡-na-prezentacji--miejsce-na-wykresy)
* [9) RozwiÄ…zywanie problemÃ³w (FAQ/Troubleshooting)](#9-rozwiÄ…zywanie-problemÃ³w-faqtroubleshooting)
* [10) Sugestie rozwoju](#10-sugestie-rozwoju)
* [11) ÅšciÄ…gawka komend](#11-Å›ciÄ…gawka-komend)

---

## 1) Cel i zakres

**Cel:** zbudowaÄ‡ dziaÅ‚ajÄ…cy system *streamingowy*, ktÃ³ry:

* generuje syntetyczne **odczyty zuÅ¼ycia energii** dla wielu gospodarstw,
* transportuje je przez **Apache Kafka**,
* wykrywa **alerty** w **Apache Spark Structured Streaming** (przekroczenia progu w oknach czasowych),
* publikuje alerty do Kafki i **prezentuje je w UI (Streamlit)**.

**Wymagania funkcjonalne:**

* StrumieÅ„ wejÅ›ciowy: `timestamp,household_id,energy_kwh`.
* Agregacja okienna i prÃ³g (sumaryczne kWh > prÃ³g).
* Dwa tryby:

  * **demo** â€“ okno 1 min, prÃ³g `0.05 kWh` (duÅ¼o alertÃ³w),
  * **prod** â€“ okno 15 min, prÃ³g `2.0 kWh` (realistycznie, alerty gÅ‚Ã³wnie w szczytach).
* Wizualizacja odczytÃ³w i alertÃ³w w czasie rzeczywistym.
* Uruchamianie na **AWS EC2** z **Docker Compose**.

---

## 2) Strategia i architektura

**Architektura:**

1. **Producer (Python)** â€“ symuluje odczyty w CSV (bez spacji):
   `YYYY-MM-DDTHH:MM:SSZ,HXYZ,0.01234`
   ZmiennoÅ›Ä‡ dobowÄ… (szczyty, poÅ‚udnie, noc) + **jitter**.

2. **Kafka** â€“ 2 tematy:

   * `energy_readings` (wejÅ›ciowy),
   * `energy_alerts` (wyjÅ›ciowy, JSON z opisem alertu).

3. **Spark Structured Streaming** â€“ parsuje CSV, nakÅ‚ada **watermark (10 min)**, liczy sumÄ™ kWh w **oknach czasowych** i filtruje przekroczenia progu â†’ zapis do Kafki (alerty JSON).

4. **UI (Streamlit)** â€“ 2 konsumenty Kafki: odczyty i alerty; podglÄ…d â€na Å¼ywoâ€.

**Dlaczego okna/progi?**
Okna wygÅ‚adzajÄ… szum, agregujÄ… sygnaÅ‚ w sensownym horyzoncie (minuty). Dwa tryby umoÅ¼liwiajÄ… zarÃ³wno szybki pokaz (demo), jak i realistycznÄ… pracÄ™ (prod).

---

## 3) Technologie i deployment

* **Docker Compose** uruchamia:

  * `kafka` (bitnami/kafka:3.7),
  * `spark-master`, `spark-worker`, `spark-submit` (Apache Spark 3.5.1),
  * `producer` (Python 3.11, kafka-python),
  * `ui` (Streamlit + kafka-python + pandas).
* **AWS EC2** (Ubuntu 24.04): dostÄ™p do UI poprzez **tunel SSH** (forwarding portÃ³w), bez wystawiania UI publicznie.

---

## 4) Struktura repo i odpowiedzialnoÅ›ci

```
Smart-Energy-Consumption-Monitor/
â”œâ”€ docker-compose.yml
â”œâ”€ .env.example            # skopiuj do .env i ustaw RUN_MODE=demo|prod itd.
â”‚
â”œâ”€ producer/
â”‚  â”œâ”€ Dockerfile
â”‚  â””â”€ simulator.py         # generator odczytÃ³w CSV â†’ Kafka: energy_readings
â”‚
â”œâ”€ spark/
â”‚  â””â”€ stream.py            # Spark job: CSVâ†’parseâ†’windowâ†’sumâ†’alertyâ†’Kafka
â”‚
â””â”€ ui/
   â”œâ”€ Dockerfile
   â””â”€ app.py               # Streamlit: podglÄ…d odczytÃ³w i alertÃ³w (Kafka)
```

### Producer â€” `producer/simulator.py`

* Generuje **H001..H{N}** co `TICK_SECONDS` w czasie **event time**.
* Model dobowy (`base_kwh_at`) + **jitter** (losowy rozrzut).
* ENV:

  * `BOOTSTRAP_SERVERS` (domyÅ›lnie `kafka:9092`)
  * `TOPIC=energy_readings`
  * `HOUSEHOLDS=50`, `TICK_SECONDS=15`, `SPEEDUP=30`, `JITTER_PCT=10`

### Spark â€” `spark/stream.py`

* **Parse CSV** â†’ `event_time`, `household_id`, `energy_kwh` + **watermark 10 min**.
* **Okna**: `window(event_time, WINDOW_DURATION, SLIDE_DURATION)`

  * demo: `1 minute` / `15 seconds` / prÃ³g `0.05`
  * prod: `15 minutes` / `15 seconds` / prÃ³g `2.0`
* **Alerty**: `kwh_window > THRESHOLD_KWH` â†’ JSON â†’ topic `energy_alerts`.
* **Checkpointy**: `CHECKPOINT_ROOT=/tmp/chk/<namespace>`.

  > Zmiana trybu/prÃ³g â†’ **wyczyÅ›Ä‡ checkpointy** (patrz sekcja 7).

### UI â€” `ui/app.py`

* Konsument `READINGS_TOPIC` (CSV) i `ALERTS_TOPIC` (JSON).
* OdÅ›wieÅ¼anie \~1 s, paginacja do `MAX_ROWS`.
* ENV: `BOOTSTRAP_SERVERS`, `READINGS_TOPIC`, `ALERTS_TOPIC`, `MAX_ROWS`.

---

## 5) Kluczowe mechanizmy i funkcje

* **Watermark (10 min)** â€“ tolerancja opÃ³ÅºnieÅ„, kontrola rozmiaru stanu.
* **Okna czasowe + slide** â€“ sumaryczne kWh w horyzoncie, mniejsza podatnoÅ›Ä‡ na szum.
* **Dwa tryby** â€“ *demo* do prezentacji i *prod* do realistycznych alertÃ³w.
* **Checkpointing** â€“ wznawialnoÅ›Ä‡ strumienia, spÃ³jnoÅ›Ä‡ offsetÃ³w.
* **Separacja odpowiedzialnoÅ›ci** â€“ generator / transport / analiza / prezentacja.

---

## 6) Uruchomienie na AWS EC2 (krok po kroku)

> **ZaÅ‚oÅ¼enia:** Ubuntu 24.04, Docker + Compose zainstalowane, Security Group ma otwarty **port 22** (SSH).

1. **Klon i konfiguracja**

```bash
git clone https://github.com/kjubig/Smart-Energy-Consumption-Monitor.git
cd Smart-Energy-Consumption-Monitor
cp .env.example .env
# Ustaw tryb:
# RUN_MODE=demo  # gÄ™ste alerty do prezentacji
# RUN_MODE=prod  # realistycznie (alerty gÅ‚Ã³wnie w szczytach)
```

2. **Start usÅ‚ug**

```bash
docker compose up -d --build kafka spark-master spark-worker producer spark-submit ui
```

3. **Weryfikacja**

```bash
docker compose ps
docker compose logs -f ui     # powinno wypisaÄ‡: URL: http://0.0.0.0:8501
```

4. **Tunel SSH z wÅ‚asnego komputera (Windows PowerShell)**

```powershell
ssh -o IdentitiesOnly=yes -i "C:\Å›cieÅ¼ka\do\klucza.pem" `
    -L 8501:localhost:8501 `
    -L 8080:localhost:8080 `
    -L 4040:localhost:4040 `
    ubuntu@PUBLICZNE_IP_EC2
```

5. **OtwÃ³rz w przeglÄ…darce**

* UI: `http://localhost:8501`
* Spark Master UI: `http://localhost:8080`
* Spark Job UI (gdy aktywny): `http://localhost:4040`

6. **Sanity check (na EC2)**

```bash
# Czy lecÄ… odczyty?
docker compose exec kafka bash -lc \
  "/opt/bitnami/kafka/bin/kafka-console-consumer.sh \
   --bootstrap-server kafka:9092 --topic energy_readings \
   --group sanity-rd --timeout-ms 6000" | head

# Czy pojawiajÄ… siÄ™ alerty?
docker compose exec kafka bash -lc \
  "/opt/bitnami/kafka/bin/kafka-console-consumer.sh \
   --bootstrap-server kafka:9092 --topic energy_alerts \
   --group sanity-alerts --timeout-ms 6000" | head
```

> **Uwaga:** W **prod** alerty naturalnie pojawiÄ… siÄ™ gÅ‚Ã³wnie w godzinach szczytu (rana/wieczÃ³r) â€” w *demo* sÄ… praktycznie od razu.

---

## 7) PrzeÅ‚Ä…czanie trybu demo/prod

Zmiany `RUN_MODE`, okna/progu **wymagajÄ… wyczyszczenia checkpointÃ³w**, aby Spark nie kontynuowaÅ‚ starego stanu.

```bash
# zatrzymaj i usuÅ„ job
docker compose stop spark-submit
docker compose rm -f spark-submit

# wyczyÅ›Ä‡ checkpointy
docker run --rm -v /tmp:/tmp alpine sh -c 'rm -rf /tmp/chk/* || true'

# uruchom ponownie job (z buildem jeÅ›li zmieniaÅ‚eÅ› kod)
docker compose up -d --build spark-submit

# opcjonalnie: upewnij siÄ™ w logach, Å¼e reguÅ‚a/tryb siÄ™ zmieniÅ‚y:
docker compose logs --tail=200 spark-submit | egrep -m1 '"rule"|\"mode\"'
# oczekuj np.: "rule":"kwh>2.0 over 15 minutes", "mode":"prod"
```

**UI pokazuje â€stareâ€ alerty?** Zresetuj offset grupy konsumenckiej UI i zrestartuj UI:

```bash
docker compose exec kafka bash -lc '
/opt/bitnami/kafka/bin/kafka-consumer-groups.sh \
  --bootstrap-server kafka:9092 \
  --group ui-streamlit \
  --topic energy_alerts \
  --reset-offsets --to-latest --execute'
docker compose restart ui
```

---

## 8) Co pokazaÄ‡ na prezentacji + miejsce na wykresy

**Minimum demonstracyjne:**

* UI (Streamlit) â€“ **odczyty** na Å¼ywo.
* UI â€“ **alerty** (w *demo* od razu; w *prod* w szczytach).

**Dodatkowe pomysÅ‚y (opcjonalnie):**

* Wykres liniowy sumy kWh w oknie dla wybranego `household_id`.
* â€Top Nâ€ gospodarstw z najwiÄ™kszÄ… liczbÄ… alertÃ³w (agregacja z logÃ³w/eksportu).
* Heatmapa `godzina Ã— gospodarstwo` (liczba alertÃ³w/suma kWh).

**Miejsce na grafiki (wklej screeny):**

### ğŸ“Š Wykres 1: StrumieÅ„ odczytÃ³w (sample)

*(tu wklej screen lub wykres)*

### ğŸš¨ Wykres 2: Alerty w czasie (demo)

*(tu wklej screen lub wykres)*

### ğŸ“ˆ Wykres 3: Alerty w prod (szczyty)

*(tu wklej screen lub wykres)*

---

## 9) RozwiÄ…zywanie problemÃ³w (FAQ/Troubleshooting)

**Kafka â€unhealthyâ€ / restart Å›rodowiska**

```bash
docker compose down -v --remove-orphans
docker network prune -f
docker compose up -d --build kafka
# po kilku sekundach: reszta usÅ‚ug
```

**Brak alertÃ³w w prod**
To **normalne poza szczytem**. Na pokaz:

* przeÅ‚Ä…cz `RUN_MODE=demo` **(i wyczyÅ›Ä‡ checkpointy)**, **albo**
* tymczasowo obniÅ¼ prÃ³g (np. `THRESHOLD_KWH=1.0`) w kodzie i przebuduj job.

**UI pokazuje stare dane**
Zresetuj offset grupy UI (sekcja 7) i zrestartuj `ui`.

**ZmieniÅ‚em tryb, ale w logach dalej â€demoâ€**
Nie zostaÅ‚y wyczyszczone checkpointy lub job wstaÅ‚ ze starym stanem. Wykonaj kroki z sekcji 7.

**DostÄ™p do UI z zewnÄ…trz**
Zalecany **tunel SSH**. Nie wystawiaj portu 8501 publicznie.

---

## 10) Sugestie rozwoju

* **Walidacja schematu** (pydantic / schema registry) dla twardszej kontroli jakoÅ›ci danych.
* **TrwaÅ‚a persystencja alertÃ³w** (np. S3/Parquet) i dashboard (Superset/Grafana).
* **Metryki Prometheus/Grafana** â€“ lag konsumentÃ³w, throughput, metryki joba.
* **Bardziej zaawansowana detekcja** â€“ odchylenie od profilu per gospodarstwo, progi dynamiczne.
* **ObsÅ‚uga bÅ‚Ä™dnych rekordÃ³w** â€“ DLQ (dead-letter topic) dla nieparsowalnych wpisÃ³w.

---

## 11) ÅšciÄ…gawka komend

```bash
# start caÅ‚oÅ›ci
docker compose up -d --build kafka spark-master spark-worker producer spark-submit ui

# status i logi
docker compose ps
docker compose logs -f spark-submit
docker compose logs -f ui

# sanity: tematy i szybkie sprawdzenie strumieni
docker compose exec kafka bash -lc "/opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list"

docker compose exec kafka bash -lc "/opt/bitnami/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server kafka:9092 --topic energy_readings --group sanity-rd --timeout-ms 6000" | head

docker compose exec kafka bash -lc "/opt/bitnami/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server kafka:9092 --topic energy_alerts --group sanity-alerts --timeout-ms 6000" | head

# przeÅ‚Ä…czenie trybu/progu (wyczyÅ›Ä‡ checkpointy!)
docker compose stop spark-submit && docker compose rm -f spark-submit
docker run --rm -v /tmp:/tmp alpine sh -c 'rm -rf /tmp/chk/* || true'
docker compose up -d --build spark-submit

# reset offsetu grupy UI i restart
docker compose exec kafka bash -lc '
/opt/bitnami/kafka/bin/kafka-consumer-groups.sh \
  --bootstrap-server kafka:9092 \
  --group ui-streamlit \
  --topic energy_alerts \
  --reset-offsets --to-latest --execute'
docker compose restart ui
```

---

**Podsumowanie:**
System *end-to-end* dziaÅ‚a: **Producer â†’ Kafka â†’ Spark â†’ Kafka (alerty) â†’ UI**. Tryb **demo** uÅ‚atwia prezentacjÄ™ (duÅ¼o zdarzeÅ„), a **prod** odwzorowuje realistyczne zachowanie (alerty gÅ‚Ã³wnie w szczytach). Instrukcje powyÅ¼ej obejmujÄ… uruchamianie, przeÅ‚Ä…czanie trybu, diagnostykÄ™ i typowe naprawy.
